# ðŸ“ DocumentaciÃ³n TÃ©cnica - Arquitectura

## VisiÃ³n General del Sistema

Sistema distribuido de microservicios para anÃ¡lisis multimodal de emociones usando Deep Learning.

## Arquitectura de Microservicios

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend (React)                      â”‚
â”‚                     http://localhost:3000                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Fusion Service (FastAPI)                        â”‚
â”‚                  Port 8004 - Gateway                         â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                  â”‚                  â”‚
    â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Facial   â”‚    â”‚  Voice   â”‚    â”‚  Text    â”‚
â”‚ Service  â”‚    â”‚ Service  â”‚    â”‚ Service  â”‚
â”‚ Port 8001â”‚    â”‚ Port 8002â”‚    â”‚ Port 8003â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚               â”‚               â”‚
     â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeepFace â”‚    â”‚ Wav2Vec2 â”‚    â”‚   BERT   â”‚
â”‚  Models  â”‚    â”‚  Models  â”‚    â”‚  Models  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Stack TecnolÃ³gico

### Backend
- **Framework**: FastAPI 0.104+
- **Servidor**: Uvicorn (ASGI)
- **ValidaciÃ³n**: Pydantic
- **ML Framework**: TensorFlow 2.15, PyTorch 2.1
- **LibrerÃ­as ML**:
  - `deepface`: AnÃ¡lisis facial
  - `transformers`: Modelos NLP
  - `librosa`: Procesamiento de audio

### Frontend
- **Framework**: React 18
- **Build Tool**: Vite 5
- **HTTP Client**: Axios
- **UI**: CSS3 puro + Lucide Icons

### Infraestructura
- **Base de datos**: PostgreSQL 15
- **Cache**: Redis 7
- **Contenedores**: Docker + Docker Compose
- **OrquestaciÃ³n**: Kubernetes (opcional)

## Modelos de Machine Learning

### 1. AnÃ¡lisis Facial (DeepFace)
```python
# Backend: services/facial/main.py
DeepFace.analyze(
    img_path=image,
    actions=['emotion'],
    enforce_detection=True,
    detector_backend='opencv'
)
```

**Arquitectura**:
- Detector: OpenCV Haar Cascade
- Modelo base: VGG-Face / FaceNet
- Output: 7 emociones con probabilidades

**Emociones detectadas**:
- happy, sad, angry, fear, surprise, disgust, neutral

### 2. AnÃ¡lisis de Voz (Wav2Vec2)
```python
# Backend: services/voice/main.py
emotion_classifier = pipeline(
    "audio-classification",
    model="ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"
)
```

**Arquitectura**:
- Preprocesamiento: Librosa (MFCC features)
- Sample rate: 16kHz
- Modelo: Wav2Vec2 Large (XLSR-53)
- Fine-tuned en: RAVDESS, CREMA-D, TESS

**Pipeline**:
1. Cargar audio â†’ 2. Resample 16kHz â†’ 3. Extraer features â†’ 4. Clasificar

### 3. AnÃ¡lisis de Texto (BERT)
```python
# Backend: services/text/main.py
# EspaÃ±ol
spanish_classifier = pipeline(
    "text-classification",
    model="finiteautomata/beto-sentiment-analysis"
)

# InglÃ©s
multilingual_classifier = pipeline(
    "text-classification",
    model="j-hartmann/emotion-english-distilroberta-base"
)
```

**Arquitectura**:
- BETO (espaÃ±ol): BERT base espaÃ±ol (110M params)
- DistilRoBERTa (inglÃ©s): RoBERTa destilado (66M params)
- TokenizaciÃ³n: WordPiece
- Max tokens: 512

**DetecciÃ³n de idioma**:
```python
def detect_language(text: str) -> str:
    # HeurÃ­stica basada en palabras comunes
    spanish_words = {'el', 'la', 'de', 'que', 'y', ...}
    english_words = {'the', 'be', 'to', 'of', 'and', ...}
    # Retorna: 'es' o 'en'
```

### 4. FusiÃ³n Multimodal
```python
# Backend: services/fusion/main.py
def weighted_fusion(results: dict, weights: dict) -> dict:
    """
    FusiÃ³n ponderada por confianza
    
    weights adaptativo:
    w_i = confidence_i / Î£(confidence_j)
    
    emotion_score = Î£(w_i * score_i)
    """
    fused_emotions = {}
    for modality, result in results.items():
        weight = weights[modality]
        for emotion, score in result['all_emotions'].items():
            fused_emotions[emotion] += score * weight
    return fused_emotions
```

**Estrategias de fusiÃ³n**:
1. **Early Fusion**: Concatenar features (no usado)
2. **Late Fusion**: Combinar predicciones (âœ“ implementado)
3. **Hybrid Fusion**: CombinaciÃ³n de ambas (futuro)

**PonderaciÃ³n adaptativa**:
- Peso proporcional a la confianza de cada modalidad
- NormalizaciÃ³n: suma de pesos = 1.0
- EmociÃ³n final: argmax(fused_emotions)

## API Endpoints

### Facial Service (8001)
```
POST /analyze/face
Content-Type: multipart/form-data

Request:
- file: Image (jpg, png)

Response:
{
  "emotion": "happy",
  "confidence": 0.87,
  "all_emotions": {"happy": 0.87, "neutral": 0.10, ...},
  "face_detected": true,
  "processing_time": 0.45
}
```

### Voice Service (8002)
```
POST /analyze/voice
Content-Type: multipart/form-data

Request:
- file: Audio (wav, mp3)

Response:
{
  "emotion": "sad",
  "confidence": 0.75,
  "all_emotions": {"sad": 0.75, "neutral": 0.15, ...},
  "audio_duration": 3.2,
  "sample_rate": 16000,
  "processing_time": 1.2
}
```

### Text Service (8003)
```
POST /analyze/text
Content-Type: application/json

Request:
{
  "text": "Me siento muy feliz hoy",
  "language": "auto"  // "es", "en", "auto"
}

Response:
{
  "emotion": "happy",
  "confidence": 0.92,
  "all_emotions": {"happy": 0.92, "neutral": 0.05, ...},
  "text_length": 25,
  "detected_language": "es",
  "processing_time": 0.15
}
```

### Fusion Service (8004)
```
POST /analyze/multimodal
Content-Type: multipart/form-data

Request:
- image: Image (optional)
- audio: Audio (optional)
- text: string (optional)
- language: string (default: "auto")

Response:
{
  "final_emotion": "happy",
  "final_confidence": 0.85,
  "all_emotions": {"happy": 0.85, "neutral": 0.10, ...},
  "facial_result": {...},
  "voice_result": {...},
  "text_result": {...},
  "modalities_used": ["facial", "text"],
  "fusion_method": "weighted_by_confidence",
  "total_processing_time": 1.8,
  "timestamp": "2025-11-25T10:30:00Z"
}
```

## Flujo de Datos

### AnÃ¡lisis Multimodal Completo

1. **Frontend**: Usuario sube imagen + audio + texto
2. **Fusion Service**: Recibe request multimodal
3. **Parallel Processing**:
   ```
   â”Œâ”€â†’ Facial Service â†’ DeepFace â†’ emotion_1
   â”œâ”€â†’ Voice Service  â†’ Wav2Vec2 â†’ emotion_2
   â””â”€â†’ Text Service   â†’ BERT     â†’ emotion_3
   ```
4. **Fusion Algorithm**:
   ```python
   weights = {
       'facial': conf_1,
       'voice': conf_2,
       'text': conf_3
   }
   final_emotion = weighted_average(emotions, weights)
   ```
5. **Response**: Retorna resultado fusionado al frontend

## Optimizaciones

### Cache (Redis)
```python
# Futuro: Cache de predicciones
@cache.memoize(timeout=3600)
def predict_emotion(image_hash):
    return model.predict(image)
```

### Batch Processing
```python
# Futuro: Procesar mÃºltiples inputs
async def analyze_batch(images: List[Image]):
    predictions = await model.predict_batch(images)
    return predictions
```

### Model Loading
```python
# Carga lazy al inicio
@app.on_event("startup")
async def load_models():
    global emotion_classifier
    emotion_classifier = pipeline("audio-classification", ...)
```

## Seguridad

### Validaciones
- TamaÃ±o mÃ¡ximo de archivos: 10MB
- Tipos MIME validados
- Rate limiting (futuro)
- Authentication (futuro)

### CORS
```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

## Performance

### Tiempos de Respuesta
- Facial: ~0.3-0.8s
- Voice: ~1.0-2.0s
- Text: ~0.1-0.3s
- Multimodal: ~1.5-3.0s (paralelo)

### Optimizaciones Futuras
- [ ] TensorRT para inferencia GPU
- [ ] QuantizaciÃ³n de modelos
- [ ] Kubernetes horizontal scaling
- [ ] Load balancing con Nginx

## Monitoreo

### Health Checks
```python
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "facial-analysis",
        "model_loaded": model is not None
    }
```

### Logging
```python
from loguru import logger

logger.add(
    "logs/app_{time}.log",
    rotation="500 MB",
    retention="10 days"
)
```

## Deployment

### Docker
```bash
docker-compose up --build
```

### Kubernetes (futuro)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: facial-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: facial-service
  template:
    spec:
      containers:
      - name: facial
        image: emotions/facial:latest
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
```

## Testing

### Unit Tests
```bash
cd backend
pytest tests/ -v
```

### Integration Tests
```python
async def test_multimodal_analysis():
    response = await client.post(
        "/analyze/multimodal",
        files={"image": image, "audio": audio},
        data={"text": "test"}
    )
    assert response.status_code == 200
    assert "final_emotion" in response.json()
```

## Referencias

- [DeepFace](https://github.com/serengil/deepface)
- [Wav2Vec2](https://huggingface.co/docs/transformers/model_doc/wav2vec2)
- [BERT](https://huggingface.co/docs/transformers/model_doc/bert)
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)
